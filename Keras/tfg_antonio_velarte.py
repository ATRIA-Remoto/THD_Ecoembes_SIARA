# -*- coding: utf-8 -*-
"""TFG_Antonio_Velarte.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17UyQVDyPLGNAbfAmPVTPkTTRc76ntlzo

# IMPORTACIÓN DE LAS LIBRERÍAS
"""

from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array
from tensorflow.keras.applications import VGG16, ResNet50V2, ResNet152V2, InceptionResNetV2, MobileNetV2, Xception
from tensorflow.keras.optimizers import RMSprop, SGD
from tensorflow.keras.layers import Input, Dropout, Flatten, Dense
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import Callback, BaseLogger, ModelCheckpoint
from tensorflow.keras.utils import plot_model
import imutils
from imutils import paths
from skimage import measure
import numpy as np
import matplotlib.pyplot as plt
import argparse
import os
import cv2
import pickle
import seaborn as sns
from google.colab.patches import cv2_imshow

"""# INICIALIZAR MODELO"""

args={"dataset":None, "model":None, "checkpoints":None, "start_epoch":None, "class_elim":None}

prueba = "/ResNet8_AZUL"

args["checkpoints"]="/content/drive/My Drive/Colab Notebooks/TFG"+prueba
args["start_epoch"]=0
#args["class_elim"]="-----"
args["class_elim"]="Nothing"
#classes = "Blue", "Box", "Can", "Chemical", Colorful", "Green", "Multiple Objects", "Nothing", "White"

#PATH DEL DATASET Y EL OUTPUT DEL MODELO
#args["dataset"] = "/content/drive/My Drive/Colab Notebooks/THD_ATRIA/Datasets/Tesis_Basura_400_300"
args["dataset"] = "/content/drive/My Drive/Colab Notebooks/IMAGENES_ATRIA"
args["model"] = "/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"modelo.h5"

#baseModel = ResNet50V2(weights="imagenet", include_top=False, input_tensor=Input(shape=(224, 224, 3)))
#ultima_capa_ent = 115
baseModel = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224, 224, 3), input_tensor=Input(shape=(224, 224, 3)))
ultima_capa_ent = 108

"""# PREPROCESAR"""

class SimpleDatasetLoader:
	def __init__(self, preprocessors=None):
		self.preprocessors = preprocessors
		if self.preprocessors is None:
			self.preprocessors = []

	def load(self, imagePaths, verbose=-1):
		data_raw = []
		data_borde = []
		data = []
		labels = []
		for (i, imagePath) in enumerate(imagePaths):
			label = imagePath.split(os.path.sep)[-2]
			image = cv2.imread(imagePath)
			data_raw.append(image)
			if self.preprocessors is not None: 
				for p in self.preprocessors:
					image = p.preprocess(image)
					### COMPROBAR QUE AGREGAMOS EL BORDE NEGRO CORRECTAMENTE
					#cv2_imshow(image)
			data.append(image)
			labels.append(label)
			if verbose > 0 and i > 0 and (i + 1) % verbose == 0:
				print("[INFO] processed {}/{}".format(i + 1,
					len(imagePaths)))
    
		return (np.array(data), np.array(labels), data_raw)

class redimensionar:
  def __init__(self, width, height, inter=cv2.INTER_AREA):
    self.width = width
    self.height = height
    self.inter = inter
    
  def preprocess(self, image):
    return cv2.resize(image, (self.width,self.height), interpolation = self.inter)

class ImageToArrayPreprocessor:
	def __init__(self, dataFormat=None):
		self.dataFormat = dataFormat

	def preprocess(self, image):
		return img_to_array(image, data_format=self.dataFormat)

class AspectAwarePreprocessor:
	def __init__(self, width, height, inter=cv2.INTER_AREA):
		self.width = width
		self.height = height
		self.inter = inter

	def preprocess(self, image):
		(h, w) = image.shape[:2]
		dW = 0
		dH = 0
		if w < h:
			image = imutils.resize(image, width=self.width,
				inter=self.inter)
			dH = int((image.shape[0] - self.height) / 2.0)
		else:
			image = imutils.resize(image, height=self.height,
				inter=self.inter)
			dW = int((image.shape[1] - self.width) / 2.0)
		(h, w) = image.shape[:2]
		image = image[dH:h - dH, dW:w - dW]

		return cv2.resize(image, (self.width, self.height),
			interpolation=self.inter)

class agregar_borde_negro:
    def __init__(self, dtype="uint8"):
        self.dtype = dtype

    def preprocess(self, image):
        (h, w) = image.shape[:2] 
        if h>w:
            max = h
        else:
            max = w
        fondo = np.zeros((max,max,3), dtype=self.dtype)

        suma = cv2.add(image, fondo[0:h, 0:w])
        fondo[0:h, 0:w] = suma

        return fondo

class aplicar_mascara:
    def __init__(self, k, sigma, valor_thres):
        self.k = 11
        self.sigma = 17
        self.valor_thres = valor_thres

    def preprocess(self, image):
      orig = image.copy()
      gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
      suav = cv2.bilateralFilter(gray, self.k, self.sigma, self.sigma)
      scr, thresh = cv2.threshold(suav, self.valor_thres, 255, cv2.THRESH_BINARY)
      thresh = cv2.erode(thresh, None, iterations=2)
      thresh = cv2.dilate(thresh, None, iterations=4)
      
      labels = measure.label(thresh, neighbors=8, background=0)
      mask = np.zeros(thresh.shape, dtype="uint8")
      for label in np.unique(labels):
        if label == 0:
          continue
        labelMask = np.zeros(thresh.shape, dtype="uint8")
        labelMask[labels == label] = 255
        numPixels = cv2.countNonZero(labelMask)
        if numPixels > 5000:
          mask = cv2.add(mask, labelMask)
        mask_applied = cv2.bitwise_and(orig,orig,mask=mask)
      return mask_applied

"""# CALLBACKS"""

class EpochCheckpoint(Callback):
	def __init__(self, outputPath, every=5, startAt=0):
		# call the parent constructor
		super(Callback, self).__init__()

		# store the base output path for the model, the number of
		# epochs that must pass before the model is serialized to
		# disk and the current epoch value
		self.outputPath = outputPath
		self.every = every
		self.intEpoch = startAt

	def on_epoch_end(self, epoch, logs={}):
		# check to see if the model should be serialized to disk
		if (self.intEpoch + 1) % self.every == 0:
			p = os.path.sep.join([self.outputPath,
				"epoch_{}.hdf5".format(self.intEpoch + 1)])
			self.model.save(p, overwrite=True)

		# increment the internal epoch counter
		self.intEpoch += 1

class monitorHistory(BaseLogger):
  def __init__(self, figPath, pickleFile=None, startAt=0):
    super(monitorHistory, self).__init__()
    self.figPath = figPath
    self.pickleFile=pickleFile
    self.startAt = startAt

  def on_train_begin(self, logs={}):
    self.History={}
    
    if self.pickleFile is not None:
      if os.path.exists(self.pickleFile):
        self.History = pickle.load(open(self.pickleFile, 'rb'))
        if self.startAt > 0:
          for k in self.History.keys():
            self.History[k] = self.History[k][:self.startAt]    
            
  def on_epoch_end(self, epoch, logs={}):
    for (k, v) in logs.items():
      l = self.History.get(k, [])
      l.append(v)
      self.History[k] = l
    if self.pickleFile is not None:
      f = open(self.pickleFile, "wb")
      pickle.dump(self.History,f)
      f.close()
    
    if len(self.History["loss"]) > 1:
      N = np.arange(0, len(self.History["loss"]))
      plt.style.use("ggplot")
      plt.figure()
      plt.plot(N, self.History["loss"], label="train_loss")
      plt.plot(N, self.History["val_loss"], label="val_loss")
      plt.plot(N, self.History["accuracy"], label="train_accuracy")
      plt.plot(N, self.History["val_accuracy"], label="val_accuracy")
      plt.title("Training Loss and Accuracy [Epoch {}]".format(
				len(self.History["loss"])))
      plt.xlabel("Epoch #")
      plt.ylabel("Loss/Accuracy")
      plt.legend()
      
      plt.savefig(self.figPath)
      plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/grafica.eps")
      plt.close()

historyCall = monitorHistory("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/grafica.png",
                             pickleFile="/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/resultados.pickle"
                             ,startAt=args["start_epoch"])
callbacks = [historyCall, EpochCheckpoint(args["checkpoints"], every=5, startAt=args["start_epoch"]),
             ModelCheckpoint("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/weights{epoch:02d}-{val_accuracy}.hdf5", 
                             monitor="val_accuracy",verbose=1, save_best_only=True)]

"""# FINE-TUNNING PARCIAL"""

class FCHeadNet:
	@staticmethod
	def build(baseModel, classes, D):
		headModel = baseModel.output
		headModel = Flatten(name="flatten")(headModel)
		headModel = Dense(D, activation="relu")(headModel)
		headModel = Dropout(0.5)(headModel)

		headModel = Dense(classes, activation="softmax")(headModel)

		return headModel

aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,
	height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
	horizontal_flip=True, fill_mode="nearest")

print("[INFO] loading images...")
imagePaths_aux = list(paths.list_images(args["dataset"]))
imagePaths = []
for i in range(len(imagePaths_aux)):
	if(not str(imagePaths_aux[i]).find(args["class_elim"])>0):
		imagePaths.append(imagePaths_aux[i])
classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]
classNames = [str(x) for x in np.unique(classNames)]

abn = agregar_borde_negro()
mask = aplicar_mascara(11,17,127)
dimen = redimensionar(300,400)
aap = AspectAwarePreprocessor(224, 224)
iap = ImageToArrayPreprocessor()

sdl = SimpleDatasetLoader(preprocessors=[dimen, iap])
(data, labels, data_raw) = sdl.load(imagePaths, verbose=100)
data = data.astype("float") / 255.0

(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)
(trainX_raw, testX_raw, trainY_raw, testY_raw) = train_test_split(data_raw, labels, test_size=0.25, random_state=42)
trainY = LabelBinarizer().fit_transform(trainY)
testY = LabelBinarizer().fit_transform(testY)

### CARGAR LAS IMAGENES DEL DATASET ATRIA
print("[INFO] loading images...")
imagePaths_aux = list(paths.list_images(args["dataset"]))
imagePaths = []
for i in range(len(imagePaths_aux)):
	if(not str(imagePaths_aux[i]).find(args["class_elim"])>0):
		imagePaths.append(imagePaths_aux[i])
classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]
classNames = [str(x) for x in np.unique(classNames)]

dimen = redimensionar(224,224)
iap = ImageToArrayPreprocessor()

sdl = SimpleDatasetLoader(preprocessors=[dimen, iap])
(data, labels, data_raw) = sdl.load(imagePaths, verbose=10)
data = data.astype("float") / 255.0

print("Imagenes totales: ",len(imagePaths_aux))
print("Imagenes de las categorías seleccionadas: ", len(imagePaths))
print("Categorías de salida: ", classNames)

#CREAMOS EL TOP DE NUESTRA RED (INCLUIDO EL CLASIFICADOR SOFTMAX)
#Y LO JUNTAMOS CON LA BASE DEL MODELO
headModel = FCHeadNet.build(baseModel, len(classNames), 256)
model = Model(inputs=baseModel.input, outputs=headModel)

### PARA GUARDAR ESTRUCTURA INTERNA DE LOS MODELOS
#path_guardar_modelo = "/content/drive/My Drive/Colab Notebooks/TFG/mobile.png"
#plot_model(model, path_guardar_modelo, show_shapes=False)

#DECLARAMOS QUE LAS CAPAS DE LA BASE NO SE ENTRENEN Y
#COMPILAMOS EL MODELO (DAMOS UN LR MUY BAJO)
for layer in baseModel.layers:
	layer.trainable = False

print("[INFO] compiling model...")
opt = RMSprop(lr=0.001)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])

#ENTREMOS LA NUEVA CABEZA DE LA RED
print("[INFO] training head...")
model.fit_generator(aug.flow(trainX, trainY, batch_size=32),
	validation_data=(testX, testY), epochs=25,
	steps_per_epoch=len(trainX) // 32, verbose=1)

#EVALUAMOS LA RED UNA VEZ ENTRENADA LA CABEZA
print("[INFO] evaluating after initialization...")
predictions = model.predict(testX, batch_size=32)
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names=classNames))

#AHORA ENTRENAMOS LAS ULTIMAS CAPAS DE CONVOLUCION CON LR MUY PEQUEÑO Y SGD
for layer in baseModel.layers[ultima_capa_ent:]:
	layer.trainable = True
print("[INFO] re-compiling model...")
opt = SGD(lr=0.001)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])

print("[INFO] fine-tuning model...")
model.fit_generator(aug.flow(trainX, trainY, batch_size=32),
	validation_data=(testX, testY), epochs=100,
	steps_per_epoch=len(trainX) // 32, verbose=1 , callbacks=callbacks)

"""# INSPECCIONAR MODELO"""

plot_model(model, show_shapes=True)

"""# RESULTADOS"""

#PARA CARGAR EL MODELO UNA VEZ ENTRENADO
#model = load_model(args["model"])
#model = load_model("/content/drive/My Drive/Colab Notebooks/TFG/10_05_exp1modelo.h5")
model = load_model("/content/drive/My Drive/Colab Notebooks/TFG/11_05_exp1modelo.h5")
#model = load_model("/content/drive/My Drive/Colab Notebooks/TFG/22_04_exp2/epoch_85.hdf5")
#model = load_model("/content/drive/My Drive/Colab Notebooks/TFG/22_04_exp4/epoch_90.hdf5")

### AÑADIR ESTO PARA EL CASO DE INFERIR RESULTADOS (de esta forma no separamos los datos en entrenamiento y validación)
''' testX = data
testY = LabelBinarizer().fit_transform(labels)
testX_raw = data_raw '''

#Evaluamos la red mediante el classification_report de sklearn

print("[INFO] evaluating after fine-tuning...")
predictions = model.predict(testX, batch_size=32)
#Mostramos los resultados obtenidos
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names=classNames))
#Guardamos los resultados en formato diccionario en un archivo pickle
''' class_report = classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names=classNames, output_dict=True) '''
#f_class = open("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/class_report.pickle", "wb")
#pickle.dump(class_report,f_class)
#f_class.close()

#GUARDAMOS EL MODELO
print("[INFO] serializing model...")
model.save(args["model"])

cm_plot_labels = ["Blue", "Box", "Can", "Chemical", "Colorful", "Green", "Multiple Objects", "Nothing", "White"]
if(args["class_elim"]!="-----"):
  cm_plot_labels.remove(args["class_elim"])

#Creamos y guardamos la matriz de confusion
cm = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1))
heat_map = sns.heatmap(cm, annot=True, cbar=True, xticklabels=cm_plot_labels, yticklabels=cm_plot_labels, cmap="Greens", linewidths=0.5)
heat_map.set_xticklabels(heat_map.get_xticklabels(), rotation=75)
plt.ylabel("True label")
plt.xlabel("Predicted label")
plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/confusion_matrix.png", bbox_inches='tight')
plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/confusion_matrix.eps", bbox_inches='tight')

#Creamos y guardamos la matriz de confusion normalizada
cm_normalized = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1), normalize='true')
heat_map_norm = sns.heatmap(cm_normalized, annot=True, cbar=True, xticklabels=cm_plot_labels, yticklabels=cm_plot_labels, cmap="Greens", linewidths=0.5)
heat_map_norm.set_xticklabels(heat_map_norm.get_xticklabels(), rotation=75)
plt.ylabel("True label")
plt.xlabel("Predicted label")
plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/confusion_matrix_normalized.png", bbox_inches='tight')
plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/confusion_matrix_normalized.eps", bbox_inches='tight')

from random import sample
plt.rcParams['axes.linewidth'] = 7

def pruebas_imagenes(imagenes, verdaderas, predichas=None):
    
    # Seleccionar 9 indices aleatorios para elegir las imagenes
    ind = sample(range(len(imagenes)),9)
    
    color = 'green'
    
    # Tomar las etiquetas verdaderas y predichas si las hay
    if predichas is None:
        etiq = verdaderas[ind]
    else:
        etiq = verdaderas[ind]
        pred = predichas[ind]
    
    # Crear la figura con 3x3 sub-plots
    fig, axes = plt.subplots(3, 3, figsize=(30,30))
    fig.subplots_adjust(hspace=0.15, wspace=0.3)

    for i, ax in enumerate(axes.flat):
        # Plotear imagen.
        muestra = imagenes[ind[i]]
        muestra = cv2.cvtColor(muestra, cv2.COLOR_BGR2RGB)
        ax.imshow(muestra)

        # Mostrar los numeros verdaderos y predichos
        if predichas is None:
            xlabel = "Real: {0}".format(etiq[i])
        else:
            xlabel = "Real: {0}, Predicha: {1}".format(etiq[i], pred[i])
            
            
            if etiq[i] != pred[i]:
                color = 'red'
            
            ax.spines['bottom'].set_color(color)
            ax.spines['top'].set_color(color)
            ax.spines['left'].set_color(color)
            ax.spines['right'].set_color(color)
            color = 'green'

        # Mostrar los numeros en el eje x
        ax.set_xlabel(xlabel, fontsize=40)
        
        # Borrar los ticks del plot
        ax.set_xticks([])
        ax.set_yticks([])
    plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/prueba_imagenes.png")
    plt.savefig("/content/drive/My Drive/Colab Notebooks/TFG"+prueba+"/prueba_imagenes.eps")
    plt.show()
    

pruebas_imagenes(imagenes=testX_raw , verdaderas=testY.argmax(axis=1) , predichas=predictions.argmax(axis=1))